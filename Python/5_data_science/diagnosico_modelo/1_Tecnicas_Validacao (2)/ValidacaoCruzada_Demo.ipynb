{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-sa-east-1.amazonaws.com/preditiva.ai/diversos/preditiva_assinatura.jpg\">\n",
    "\n",
    "# Técnicas de Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#métrica de performance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#modelo a ser treinado\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_rh.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionamento usando K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação das variáveis explicativas e a variável target\n",
    "x = df.drop('Funcionário_deixou_a_empresa', axis=1)\n",
    "y = df['Funcionário_deixou_a_empresa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particoes = KFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in particoes.split(x.head(10)):\n",
    "    print(train_index, len(train_index), test_index, len(test_index)) # mostra os índices do DataFrame X com 10 linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que o percentual da base que fica para teste é 1/k. **No exemplo, se k = 5 então o particionamento fica em 80% para Treino e 20% para Teste.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino de modelos usando K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particoes = KFold(n_splits = 5, shuffle = True, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação das variáveis explicativas e a variável target\n",
    "x = df.drop('Funcionário_deixou_a_empresa', axis=1)\n",
    "y = df['Funcionário_deixou_a_empresa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_train = []\n",
    "roc_test = []\n",
    "\n",
    "# Criando as variáveis dummies\n",
    "x = pd.get_dummies(x)\n",
    "\n",
    "for train_index, test_index in particoes.split(x):\n",
    "    \n",
    "    # Separa a base    \n",
    "    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #Treina o modelo\n",
    "    modelo = DecisionTreeClassifier(max_depth=2)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # AUC em Treino\n",
    "    prob_train = modelo.predict_proba(X_train)[:,1]\n",
    "    roc_train.append(roc_auc_score(y_train, prob_train))\n",
    "    \n",
    "    # AUC em Teste\n",
    "    prob_test = modelo.predict_proba(X_test)[:,1]\n",
    "    roc_test.append(roc_auc_score(y_test, prob_test))\n",
    "    \n",
    "    \n",
    "resultado = pd.DataFrame({\"AUC em Treino\":roc_train, \"AUC em Teste\":roc_test})\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado.describe().loc[['mean','std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor médio de AUC em Teste ficou em 0,69 com um desvio padrão maior que o AUC de Treino. Perceba que se não usássemos validação cruzada, poderíamos cair na primeira partição e achar que o modelo não generaliza bem (AUC em Teste = 0,58) quando na média ele generaliza (AUC médio em Teste = 0,69)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como melhorar a Validação Cruzada?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dos problemas da aleatoriedade do particionamento é que não garantimos que Treino e Teste terão a mesma **\"Distribuição\"**. Veja um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_train = []\n",
    "roc_test = []\n",
    "target_train = []\n",
    "target_test = []\n",
    "\n",
    "# Criando as variáveis dummies\n",
    "x = pd.get_dummies(x)\n",
    "\n",
    "for train_index, test_index in particoes.split(x):\n",
    "    \n",
    "    # Separa a base    \n",
    "    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Target em Treino e Teste\n",
    "    target_train.append(np.where(y_train == 'Sim',1,0).mean())\n",
    "    target_test.append(np.where(y_test == 'Sim',1,0).mean())\n",
    "    \n",
    "    #Treina o modelo\n",
    "    \n",
    "    modelo = DecisionTreeClassifier(max_depth=2)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # AUC em Treino\n",
    "    prob_train = modelo.predict_proba(X_train)[:,1]\n",
    "    roc_train.append(roc_auc_score(y_train, prob_train))\n",
    "    \n",
    "    # AUC em Teste\n",
    "    prob_test = modelo.predict_proba(X_test)[:,1]\n",
    "    roc_test.append(roc_auc_score(y_test, prob_test))\n",
    "    \n",
    "    \n",
    "resultado = pd.DataFrame({\"Target em Treino\":target_train,\"Target em Teste\":target_test,\"AUC em Treino\":roc_train, \"AUC em Teste\":roc_test})\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que a **distribuição do Target entre modelos não é o mesmo**... Isso pode afetar a mensuração da métrica de performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold com Estratificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um forma de minimizar esse problema da diferença de Targets entre as partições é \"estratificar\" as partições, isto é, garantir que as partições de treino e teste tenha aproximadamente a mesma quantidade proporcional de Targets. Veja como fazer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particoes = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação das variáveis explicativas e a variável target\n",
    "x = df.drop('Funcionário_deixou_a_empresa', axis=1)\n",
    "y = df['Funcionário_deixou_a_empresa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_train = []\n",
    "roc_test = []\n",
    "target_train = []\n",
    "target_test = []\n",
    "\n",
    "# Criando as variáveis dummies\n",
    "x = pd.get_dummies(x)\n",
    "\n",
    "for train_index, test_index in particoes.split(x,y): # Aqui colocamos o parâmetro y para que o particionador saiba calcular as proporções\n",
    "    \n",
    "    # Separa a base    \n",
    "    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Target em Treino e Teste\n",
    "    target_train.append(np.where(y_train == 'Sim',1,0).mean())\n",
    "    target_test.append(np.where(y_test == 'Sim',1,0).mean())\n",
    "    \n",
    "    #Treina o modelo\n",
    "    \n",
    "    modelo = DecisionTreeClassifier(max_depth=2)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # AUC em Treino\n",
    "    prob_train = modelo.predict_proba(X_train)[:,1]\n",
    "    roc_train.append(roc_auc_score(y_train, prob_train))\n",
    "    \n",
    "    # AUC em Teste\n",
    "    prob_test = modelo.predict_proba(X_test)[:,1]\n",
    "    roc_test.append(roc_auc_score(y_test, prob_test))\n",
    "    \n",
    "    \n",
    "resultado2 = pd.DataFrame({\"Target em Treino\":target_train,\"Target em Teste\":target_test,\"AUC em Treino\":roc_train, \"AUC em Teste\":roc_test})\n",
    "resultado2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja como os Targets ficaram. Agora a comparação entre os modelos ficou mais justa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold sem estratificação\n",
    "resultado.describe().loc[['mean','std']][['AUC em Treino','AUC em Teste']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold COM estratificação\n",
    "resultado2.describe().loc[['mean','std']][['AUC em Treino','AUC em Teste']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja como **a variação do AUC em Teste diminuiu bastante**. Isso mostra que a variação do AUC em Teste anterior estava sendo impactada pelas distribuições diferentes entre os Targets em Treino e Teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dica:** A estratificação é muito indicada nos casos em que temos uma base muito pequena ou com o target desbalanceado. Desta forma garantimos que ao menos teremos partições com um número próximo de classes 1 e 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para saber mais**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem outros tipos de validação cruzada menos frequentes na prática. Confira mais em: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
